#!/usr/bin/env node

/**
 * Script de prueba para validar las correcciones del sistema Claude
 * Verifica que las estimaciones de tokens y chunking funcionen correctamente
 */

const fs = require('fs');
const path = require('path');

console.log('ðŸ§ª === SCRIPT DE VALIDACIÃ“N DE CORRECCIONES CLAUDE ===\n');

// Simular configuraciÃ³n
const modelConfig = {
  claude: {
    maxContextTokens: 200000,
    maxDocumentTokens: 180000,
    circuitBreakerThreshold: 5,
    rateLimits: {
      rpm: 50,
      itpm: 40000,
      otpm: 8000
    }
  }
};

// FunciÃ³n de estimaciÃ³n corregida
function estimateTokens(text) {
  return Math.ceil(text.length / 2.3); // Nueva ratio corregida
}

// FunciÃ³n de chunking strategy corregida
function determineChunkingStrategy(documentText, prompt = '') {
  const docLength = documentText.length;
  const estimatedTokens = estimateTokens(documentText);
  const promptTokens = estimateTokens(prompt);
  const totalTokens = estimatedTokens + promptTokens;

  console.log(`ðŸ“ Document analysis: ${docLength} chars, ~${estimatedTokens} tokens, prompt: ${promptTokens} tokens`);

  // VerificaciÃ³n adicional de seguridad
  const maxSafeTokens = modelConfig.claude.maxDocumentTokens || 180000;
  if (estimatedTokens > maxSafeTokens) {
    console.log(`âš ï¸ Document exceeds safe token limit (${estimatedTokens} > ${maxSafeTokens}) - forcing chunking`);
    return {
      useChunking: true,
      maxChunkTokens: 50000,
      overlapTokens: 2000,
      reason: `Document exceeds safe token limit (${estimatedTokens} tokens) - forced chunking`
    };
  }

  // Detect problematic document sizes
  const isVeryLargeDoc = docLength > 500000;
  const isLargeDoc = docLength > 400000;
  
  if (isVeryLargeDoc) {
    console.log(`ðŸš¨ Very large document detected (${docLength} chars) - forcing aggressive chunking`);
    return {
      useChunking: true,
      maxChunkTokens: 60000,
      overlapTokens: 3000,
      reason: `Very large document (${docLength} chars) - aggressive chunking applied`
    };
  }

  // Progressive safety margins
  const safetyMargin = isLargeDoc ? 0.5 : (docLength > 200000 ? 0.65 : 0.8);
  
  if (totalTokens <= (modelConfig.claude.maxContextTokens * safetyMargin)) {
    return {
      useChunking: false,
      maxChunkTokens: 0,
      overlapTokens: 0,
      reason: `Document fits in context (${totalTokens} tokens < ${Math.floor(modelConfig.claude.maxContextTokens * safetyMargin)} limit, safety: ${Math.round(safetyMargin * 100)}%)`
    };
  }

  // Progressive chunk sizing
  let baseChunkSize;
  if (isLargeDoc) {
    baseChunkSize = 80000;
  } else if (docLength > 300000) {
    baseChunkSize = 100000;
  } else if (docLength > 200000) {
    baseChunkSize = 120000;
  } else {
    baseChunkSize = 140000;
  }

  return {
    useChunking: true,
    maxChunkTokens: baseChunkSize,
    overlapTokens: isLargeDoc ? 2000 : 1000,
    reason: `Document too large (${totalTokens} tokens). Smart chunking: ${baseChunkSize} tokens/chunk`
  };
}

// Tests
const testCases = [
  {
    name: "Documento pequeÃ±o (50K chars)",
    text: 'A'.repeat(50000),
    expectedChunking: false
  },
  {
    name: "Documento mediano (200K chars)",
    text: 'A'.repeat(200000),
    expectedChunking: false // DeberÃ­a caber con safety margin 0.65
  },
  {
    name: "Documento grande (400K chars)",
    text: 'A'.repeat(400000),
    expectedChunking: true // Safety margin 0.5
  },
  {
    name: "Documento problemÃ¡tico (549K chars - igual al del log)",
    text: 'A'.repeat(548957), // TamaÃ±o exacto del documento que fallÃ³
    expectedChunking: true
  },
  {
    name: "Documento muy grande (600K chars)",
    text: 'A'.repeat(600000),
    expectedChunking: true // Forzar chunking agresivo
  }
];

console.log('ðŸ”¬ EJECUTANDO PRUEBAS...\n');

let passed = 0;
let total = testCases.length;

testCases.forEach((testCase, index) => {
  console.log(`\nðŸ“‹ Test ${index + 1}: ${testCase.name}`);
  console.log(`   TamaÃ±o: ${testCase.text.length.toLocaleString()} caracteres`);
  
  const strategy = determineChunkingStrategy(testCase.text);
  const actualChunking = strategy.useChunking;
  
  console.log(`   Estrategia: ${strategy.reason}`);
  console.log(`   Esperado chunking: ${testCase.expectedChunking}, Actual: ${actualChunking}`);
  
  if (actualChunking === testCase.expectedChunking) {
    console.log(`   âœ… PASS`);
    passed++;
  } else {
    console.log(`   âŒ FAIL`);
  }
  
  if (strategy.useChunking) {
    console.log(`   ðŸ“Š ConfiguraciÃ³n: ${strategy.maxChunkTokens} tokens/chunk, ${strategy.overlapTokens} overlap`);
  }
});

console.log('\n' + '='.repeat(50));
console.log(`ðŸŽ¯ RESULTADOS FINALES: ${passed}/${total} pruebas pasaron`);

if (passed === total) {
  console.log('ðŸŽ‰ Â¡TODAS LAS CORRECCIONES FUNCIONAN CORRECTAMENTE!');
  console.log('\nðŸ“‹ RESUMEN DE CORRECCIONES APLICADAS:');
  console.log('âœ… Token estimation: 3.5 â†’ 2.3 chars/token');
  console.log('âœ… Safety margins: Progresivos por tamaÃ±o de documento');
  console.log('âœ… Chunking forzado: Para docs >500K chars');
  console.log('âœ… LÃ­mite de seguridad: <180K tokens estimados');
  console.log('âœ… Rate limits: MÃ¡s permisivos (40K ITPM)');
  console.log('âœ… Circuit breaker: Umbral configurable (5 fallos)');
  console.log('âœ… Validation triple: Corregido fallback de modelos');
} else {
  console.log('âš ï¸ Algunas pruebas fallaron. Revisar implementaciÃ³n.');
  process.exit(1);
}

console.log('\nðŸš€ Para aplicar en producciÃ³n:');
console.log('1. npm run build');
console.log('2. npm run start:prod');
console.log('3. Monitorear logs las primeras horas');
console.log('4. Ajustar configuraciÃ³n segÃºn necesidad');