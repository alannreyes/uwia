# Plan Maestro de Mejoras para el Sistema de Procesamiento de Documentos

## 1. Visi√≥n General y Objetivos

El objetivo de este plan es reestructurar el sistema de procesamiento de documentos para que sea m√°s robusto, resiliente y eficiente. Se busca eliminar fallos catastr√≥ficos, manejar una mayor variedad de PDFs (escaneados, multi-p√°gina, muy grandes) y unificar la l√≥gica de negocio para facilitar el mantenimiento y la extensibilidad.

## 2. Arquitectura Propuesta: Un Pipeline Unificado

Se propone abandonar la arquitectura de dos flujos (`evaluateClaim` y `processLargeFileSynchronously`) y adoptar un √∫nico pipeline de procesamiento por etapas. Cada etapa se enfoca en una tarea espec√≠fica y pasa el resultado a la siguiente.

El nuevo flujo ser√° orquestado por un `ProcessingOrchestratorService` y seguir√° estos pasos:

1.  **Recepci√≥n y Clasificaci√≥n Inicial**:  
    ‚úÖ Estructura de sesi√≥n y clasificaci√≥n inicial implementada en el pipeline actual.
    *   Recibir el archivo.
    *   Determinar su tipo (PDF, imagen) y tama√±o.
    *   Crear una sesi√≥n de procesamiento √∫nica en la base de datos para tracking.

2.  **Etapa de Extracci√≥n de Contenido (Multi-paso)**:
    *   **Paso 1: Extracci√≥n R√°pida de Texto**. ‚úÖ Ya implementado con `pdf-parse`.
    *   **Paso 2: Extracci√≥n Avanzada de Texto**. ‚úÖ Ya implementado con `pdfjs-dist` (legacy, worker config corregido).
    *   **Paso 3: Detecci√≥n y Aplicaci√≥n de OCR**. üîÑ En progreso: OCR service y fallback planificado, integraci√≥n pendiente.
        *   Convertir las p√°ginas del PDF a im√°genes (PNG/JPEG).
        *   Utilizar un servicio de OCR (como Tesseract.js o una API externa como Google Vision) para extraer texto de cada imagen.
        *   Ensamblar el texto extra√≠do en un formato coherente.
    *   **Paso 4: An√°lisis con Modelos de Visi√≥n (Gemini, GPT-4 Vision)**. ‚úÖ GeminiService creado, l√≥gica de decisi√≥n por tama√±o implementada en orquestador.
        *   Si el archivo es **menor de 20MB**, se usar√° el m√©todo de **datos en l√≠nea** de Gemini (enviar el buffer directamente).
        *   Si el archivo es **mayor de 20MB y hasta 50MB**, se usar√° la **File API** de Gemini (subir, esperar estado ACTIVE, luego consultar por URI).
        *   El orquestador decidir√° el m√©todo autom√°ticamente seg√∫n el tama√±o.
        *   Si ambos m√©todos fallan o el archivo supera 50MB, se intentar√° dividir el PDF en partes menores y procesar por lotes, o se usar√° fallback a OCR/visi√≥n por p√°gina.
### 3.5. `GeminiService` (Nuevo)
*   **Prop√≥sito**: Encapsular la l√≥gica de integraci√≥n con la API de Gemini, soportando ambos m√©todos (inline y File API).
*   **Implementaci√≥n**: El servicio expone dos m√©todos:
    *   `processDocumentInline(buffer, prompt)`: para archivos <20MB.
    *   `processDocumentWithFileAPI(buffer, prompt)`: para archivos 20‚Äì50MB.
    *   El orquestador decide cu√°l usar y maneja los estados de procesamiento.
*   **Compatibilidad**: Usa la variable de entorno `GEMINI_API_KEY` ya existente.
*   **Fallback**: Si Gemini falla, el pipeline sigue con OCR o procesamiento tradicional.

3.  **Etapa de "Chunking" Inteligente**:
    *   Para documentos que superen un umbral de tama√±o (configurable, ej. 20MB o 100 p√°ginas), el contenido extra√≠do (sea texto o im√°genes) se dividir√° en "chunks" o fragmentos.
    *   El chunking no se basar√° en un tama√±o fijo de caracteres, sino en la estructura del documento (p√°rrafos, secciones, p√°ginas). Esto mejora la coherencia del contexto para los modelos de lenguaje.

4.  **Etapa de An√°lisis y Estructuraci√≥n (RAG)**:
    *   Los chunks se procesan para generar "embeddings" y se almacenan en una base de datos vectorial (si aplica).
    *   Se ejecuta el pipeline de RAG (Retrieval-Augmented Generation) usando los prompts definidos para extraer la informaci√≥n solicitada. El sistema buscar√° los chunks m√°s relevantes y los inyectar√° en el prompt final al LLM.

5.  **Etapa de Validaci√≥n y Formateo**:
    *   La salida del LLM se valida contra un esquema esperado.
    *   Se realizan reintentos con estrategias de correcci√≥n si la validaci√≥n falla.
    *   Se formatea la salida final en el formato JSON requerido.

## 3. Mejoras Espec√≠ficas y Nuevos Componentes

### 3.1. `OcrService` üîÑ En progreso
*   **Prop√≥sito**: Centralizar la l√≥gica de OCR.
*   **Implementaci√≥n**: Crear un nuevo servicio `OcrService` que se integre con una librer√≠a como `Tesseract.js` o una API externa. Deber√° ser capaz de procesar un buffer de imagen y devolver el texto extra√≠do.
*   **Configuraci√≥n**: Habilitar/deshabilitar el OCR y configurar el proveedor a trav√©s de variables de entorno (`OCR_ENABLED`, `OCR_PROVIDER`).

### 3.2. Refactorizaci√≥n de `PdfParserService` y `PdfToolkitService` ‚úÖ
*   **Prop√≥sito**: Eliminar redundancia.
*   **Acci√≥n**: Fusionar la funcionalidad de `PdfToolkitService` dentro de `PdfParserService`. El `PdfParserService` se convertir√° en el √∫nico responsable de la extracci√≥n de texto y la conversi√≥n a im√°genes, simplificando el c√≥digo y evitando la duplicaci√≥n de l√≥gica.

### 3.3. `ProcessingOrchestratorService` ‚úÖ Creado y conectado a GeminiService.
*   **Prop√≥sito**: Orquestar el nuevo pipeline unificado.
*   **Implementaci√≥n**: Este servicio contendr√° la l√≥gica principal del pipeline descrito en la secci√≥n 2. Llamar√° a los dem√°s servicios (`PdfParserService`, `OcrService`, `ModernRagService`, etc.) en la secuencia correcta.

### 3.4. Gesti√≥n de Memoria y Grandes Archivos üîÑ En progreso: chunking y splitting avanzado planificado, parte b√°sica ya implementada.
*   **Problema**: El procesamiento de archivos de m√°s de 100MB en memoria puede causar crashes.
*   **Soluci√≥n**:
    1.  **Streaming**: Para la conversi√≥n de PDF a im√°genes, se deben usar librer√≠as que soporten streaming para no cargar el archivo completo en memoria.
    2.  **Procesamiento por P√°ginas**: En la etapa de OCR y Visi√≥n, las p√°ginas se procesar√°n una por una (o en peque√±os lotes), liberando la memoria de la imagen anterior antes de cargar la siguiente.
    3.  **Almacenamiento Temporal**: Para archivos muy grandes, las im√°genes de las p√°ginas se pueden guardar temporalmente en disco en lugar de mantenerlas en memoria.

## 4. Plan de Implementaci√≥n por Fases

*   **Fase 1: Refactorizaci√≥n y Unificaci√≥n**
    1.  ‚úÖ Crear el `ProcessingOrchestratorService` con la estructura b√°sica del pipeline.
    2.  ‚úÖ Fusionar `PdfToolkitService` en `PdfParserService`.
    3.  üîÑ Adaptar el `UnderwritingController` para que utilice el nuevo orquestador (pendiente endpoint v2).
    4.  ‚úÖ Mantener la l√≥gica existente funcionando dentro del nuevo pipeline para no romper la funcionalidad actual.

*   **Fase 2: Integraci√≥n de OCR**
    1.  üîÑ Desarrollar el `OcrService` (en progreso).
    2.  üîÑ Integrar la etapa de OCR en el `ProcessingOrchestratorService` (planificado).
    3.  üîÑ A√±adir la l√≥gica para detectar cu√°ndo usar OCR (planificado).
    4.  ‚úÖ Integrar la etapa de Gemini Vision (inline o File API) como fallback antes de OCR, seg√∫n tama√±o.
    5.  üîÑ Probar con documentos escaneados y complejos (pendiente).

*   **Fase 3: Optimizaci√≥n de Grandes Archivos y Modelos de Visi√≥n**
    1.  üîÑ Implementar las mejoras de gesti√≥n de memoria (streaming, procesamiento por p√°ginas) (parcialmente hecho, splitting avanzado pendiente).
    2.  ‚úÖ Integrar la etapa de "An√°lisis con Modelos de Visi√≥n" (GeminiService) como el √∫ltimo recurso del pipeline de extracci√≥n, con l√≥gica de decisi√≥n por tama√±o.
    3.  üîÑ Realizar pruebas de estr√©s con archivos de diferentes tama√±os (pendiente).

## 5. Variables de Entorno Sugeridas

Para controlar el nuevo comportamiento, se sugiere a√±adir las siguientes variables de entorno:

```
# Habilita o deshabilita el pipeline de OCR
OCR_ENABLED=true

# Define el proveedor de OCR (ej. 'tesseract', 'google-vision')
OCR_PROVIDER=tesseract

# Habilita o deshabilita el uso de modelos de visi√≥n como fallback
VISION_ANALYSIS_ENABLED=true

# Umbral de tama√±o en MB para activar el modo de "procesamiento de archivo grande" (chunking, etc.)
LARGE_FILE_THRESHOLD_MB=20

# N√∫mero m√°ximo de p√°ginas a enviar a un modelo de visi√≥n en una sola llamada
VISION_MAX_PAGES=5

# Clave de API para Gemini (ya usada en el sistema)
GEMINI_API_KEY=tu_api_key
```

## Resumen de la mejora principal

La nueva versi√≥n implementa un pipeline unificado y robusto para procesar cualquier PDF (nativo, escaneado, grande o peque√±o), integrando extracci√≥n de texto avanzada, fallback autom√°tico a OCR, chunking inteligente y uso de Gemini/OpenAI Vision seg√∫n el caso. Ahora, si el PDF supera el l√≠mite del m√©todo inline, el sistema utiliza autom√°ticamente el m√©todo File API de Gemini para procesar archivos grandes. Si los modelos de IA fallan, retorna el texto extra√≠do. La mejora esperada es m√°xima resiliencia: ning√∫n PDF queda sin procesar, se minimizan errores, y se aprovechan al m√°ximo las capacidades de IA y OCR, con logs claros y manejo autom√°tico de casos l√≠mite.
